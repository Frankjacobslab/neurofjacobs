# Snakefile
# Tells which files to generate as specified by the rule 'all'

# Snakefile to quality check and estimate counts from RNA-Seq data on a reference genome (e.g. human genome hg19)
# Tells which files to generate as specified by the rule 'all'

import os
import subprocess

#########################
## Pipeline configuration
#########################

# configuration file
configfile: "config.yaml"

# working directory (o clean afterwards)
WORKING_DIR = config["workdir"]

# Number of CPU (threads)
THREADS = config["threads"]

# Trimmomatic
ADAPTERFILE = config["trimmomatic"]["adapters"]
TRIMMOMATIC = config["trimmomatic"]["jarfile"]

##################
## Desired outputs
##################
FASTQC_REPORTS = expand("fastqc/trimmed/{sample}/{pair}/{sample}_{pair}_fastqc.html",sample=config["samples"],pair=["forward","reverse"])
MAPPING_LOGS = expand("results/mappinglogs/{sample}_Log.final.out",sample=config["samples"]) 
COUNTS = ["results/counts/gene_counts.txt","results/counts/repeat_counts.txt"] 
BIGWIGS = expand( "results/bigwig/{sample}_Signal.{uniqueness}.{strand}.normalized.bw",sample=config["samples"],uniqueness=["Unique","UniqueMultiple"],strand=["str1","str2"])

MASTER_FILES = ["results/Snakefile","results/config.yaml"]

rule all:
	input:
		MAPPING_LOGS,
		COUNTS,
		BIGWIGS,
		MASTER_FILES 
	message: "RNA-Seq pipeline has been successfully run"

#######################
##  copy master files
#######################
rule copy_master_files:
    output:
        "results/Snakefile",
        "results/config.yaml"
    message:"copying master files (Snakefile and configuration files)"
    shell:
        "cp Snakefile results/;"
        "cp config.yaml results/"

#########
## bigWig
#########
rule convert_to_bigWig: 
    input:
        bedgraph = WORKING_DIR + "mapped/{sample}_Signal.{uniqueness}.{strand}.out.sorted.bg",
        chroms = "chromSizes.tab"
    output:
        "results/bigwig/{sample}_Signal.{uniqueness}.{strand}.normalized.bw"
    message:"converting strand-specific bedGraph files for {wildcards.sample}, {wildcards.uniqueness} reads and {wildcards.strand} strand to bigWig format"
    shell:
        "bedGraphToBigWig {input.bedgraph} {input.chroms} {output}"        

rule generate_chrom_sizes:
    input:
        genome2bit = config["refseqs"]["genome2bit"]
    output:
        "chromSizes.tab"
    message:"generating chromosome sizes"
    shell:"twoBitInfo {input} {output}"

rule sort_bedgraph:
    input:
         WORKING_DIR + "mapped/{sample}_Signal.{uniqueness}.{strand}.out.bg"
    output:
         WORKING_DIR + "mapped/{sample}_Signal.{uniqueness}.{strand}.out.sorted.bg"
    message:"sorting {wildcards.sample} bedGraph file for strand {wildcards.strand} and {wildcards.uniqueness} reads"
    shell:
        "bedSort {input} {output}"   

################################################
## Count read alignments per feature (e.g. gene)
################################################
rule count_repeats:
    input:
        bams = expand(WORKING_DIR + "mapped/{sample}_Aligned.sortedByCoord.out.bam",sample=config["samples"].keys()),
        annotation = config["annotations"]["gtf4repeats"],
        genome = config["refseqs"]["genomefasta"]
    output:
        "results/counts/repeat_counts.txt"
    message:"summarizing read counts for repeats"
    shell:
        "featureCounts "
        "-f "				# summarize only at exon level
        #"-t exon "			# specify how to count reads at feature level (e.g. exon)
        "-T {THREADS} "
        "-G {input.genome} "		# ref genome sequence
        "-a {input.annotation} "	# annotation 
        "-F GTF "			# SAF or GTF (by default GTF)
        "-o {output} "
        "{input.bams}"               	# can process more than one BAM file at once 

rule count_genes:
    input:
        bams = expand(WORKING_DIR + "mapped/{sample}_Aligned.sortedByCoord.out.bam",sample=config["samples"].keys()),
        annotation = config["annotations"]["refseqFromSubread"],
        genome = config["refseqs"]["genomefasta"]
    output:
        "results/counts/gene_counts.txt"
    message:"summarizing read counts for genes"
    shell:
        "featureCounts "
        "-t exon "			# specify how to count reads at feature level (e.g. exon)
        "-g gene_id " 			# specify how to count reads at meta-feature level (e.g. gene)
        "-T {THREADS} "
        "-G {input.genome} "		# ref genome sequence
        "-a {input.annotation} "	# annotation 
        "-F SAF "			# SAF or GTF (by default GTF)
        "-o {output} "
        "{input.bams}"               	# can process more than one BAM file at once 
        


#############################
# Genome alignment using STAR
#############################
rule copy_mapping_logs:
    input:
        WORKING_DIR + "mapped/{sample}_Log.final.out"
    output:
        "results/mappinglogs/{sample}_Log.final.out" 
    message:"moving mapping log for {wildcards.sample} in {output}"
    shell:"mv {input} {output}"

rule map_to_genome_using_STAR:
    input:
        ref = "star2pass/",
        forward = WORKING_DIR + "trimmed/{sample}_forward.fastq",
        reverse = WORKING_DIR + "trimmed/{sample}_reverse.fastq"
    output:
        WORKING_DIR + "mapped/{sample}_Aligned.sortedByCoord.out.bam",
        WORKING_DIR + "mapped/{sample}_Aligned.sortedByCoord.out.bam.bai",
        WORKING_DIR + "mapped/{sample}_Log.final.out",
	WORKING_DIR + "mapped/{sample}_Signal.Unique.str1.out.bg",
        WORKING_DIR + "mapped/{sample}_Signal.Unique.str2.out.bg",
        WORKING_DIR + "mapped/{sample}_Signal.UniqueMultiple.str1.out.bg",
        WORKING_DIR + "mapped/{sample}_Signal.UniqueMultiple.str2.out.bg"        
    message:"mapping the {wildcards.sample} reads to genome"
    params:
        prefix = WORKING_DIR + "mapped/{sample}_",
        maxmismatches = config["star"]["mismatches"],
        unmapped = config["star"]["unmapped"]	,
        multimappers = config["star"]["multimappers"],
        matchNminoverLread = config["star"]["matchminoverlengthread"],
	outSamType = config["star"]["samtype"],
        outWigType = config["star"]["outwigtype"],
        outWigStrand = config["star"]["outwigstrand"],
        outWigNorm = config["star"]["outwignorm"]
    shell:
            "STAR --genomeDir {input.ref} "
            "--readFilesIn {input.forward} {input.reverse} "
            "--outFilterMultimapNmax {params.multimappers} "
            "--outFilterMismatchNmax {params.maxmismatches} "
            "--outFilterMatchNminOverLread {params.matchNminoverLread} "
            "--alignEndsType EndToEnd "
            "--runThreadN {THREADS} "
            "--outReadsUnmapped {params.unmapped} "
            "--outFileNamePrefix {params.prefix} "
            "--outSAMtype {params.outSamType} "
            "--outWigType {params.outWigType} "
            "--outWigStrand {params.outWigStrand} "
            "--outWigNorm {params.outWigNorm};"
            "samtools index {output[0]}"

#####################################################################
## STAR 2-pass: genome indexing + splice junctions database generation 
#####################################################################
rule star2pass_index:
    input:
        sjdb = "./star1pass/SJ.concatenated.out.tab",
        directory = "star2pass/", 
        ref= config["refseqs"]["genomefasta"],
        gtf = config["annotations"]["gtf4genes"]
    output:
        STAR_2PASS = ["star2pass/"+f for f in ["chrLength.txt","chrNameLength.txt","chrName.txt","chrStart.txt","Genome","genomeParameters.txt","SA","SAindex"]]
    message: "STAR 2nd pass: generating genome index"	
    shell:
        "STAR --runMode genomeGenerate "
        "--genomeDir {input.directory} "
        "--genomeFastaFiles {input.ref} "
        "--runThreadN {THREADS} "
        "--sjdbFileChrStartEnd {input.sjdb} "
        "--sjdbOverhang 99 "
        "--sjdbGTFfile {input.gtf};"
        "touch -h {output}"

rule create_star2pass_directory:
    output:"star2pass/"
    message:"create directory for star2pass"
    shell:"mkdir -p star2pass/"

rule concatenate_sjdb:
    input:
        expand("./star1pass/{sample}_SJ.out.tab",sample=config["samples"].keys()),
    output:
        "./star1pass/SJ.concatenated.out.tab"
    message:"concatenating splice junctions from different samples "
    shell:"cat {input} >> {output}"

rule star1pass_align:
    input:
        forward = WORKING_DIR + "trimmed/{sample}_forward.fastq",
        reverse = WORKING_DIR + "trimmed/{sample}_reverse.fastq", 
        ref = "star_index/"
    output:
        "./star1pass/{sample}_SJ.out.tab",
        temp("./star1pass/{sample}_Aligned.out.sam")
    message:"STAR 1st pass: aligning {wildcards.sample} reads to generate splice junction files"
    params:"./star1pass/{sample}_"	
    shell: 		
        "STAR --runMode alignReads "
        "--genomeDir {input.ref} "
        "--readFilesIn {input.forward} {input.reverse} "
        "--outFileNamePrefix {params} "
        "--outFilterIntronMotifs RemoveNoncanonical "
        "--runThreadN {THREADS}"

 # sdjbOverhang specifies the length of the genomic sequence around the annotated junction to be used in constructing the splie junctions database. Ideally this length should be equal to ReadLength-1
rule star_genome_index:
    input:
        genome = config["refseqs"]["genomefasta"],
        gtf = config["annotations"]["gtf4genes"]
    output:
        "star_index/"
    message:"generation STAR genome index" 
    params:"star_index/"
    shell:
        "STAR --runMode genomeGenerate "
        "--genomeDir {params} "
        "--genomeFastaFiles {input.genome} "
        "--runThreadN {THREADS} "
        "--sjdbOverhang 99 "
        "-sjdbGTFfile {input.gtf}"

################################
## Fastqc reports after trimming
################################
rule fastqc_after_trimming:
    input:
        WORKING_DIR + "trimmed/{sample}_{pair}.fastq"
    output:
        "fastqc/trimmed/{sample}/{pair}/{sample}_{pair}_fastqc.html"
    message:"generating fastqc report for trimmed reverse {wildcards.sample} reads"
    params:
        "fastqc/trimmed/{sample}/{pair}/"
    shell:
        "fastqc --threads {THREADS} --outdir={params} {input}"
    
###########
## Trimming
###########
rule trimmomaticPaired:
    input:
        ADAPTERFILE,
        forward = lambda wildcards: config["fastqdir"] + config["samples"][wildcards.sample]["forward"],
        reverse = lambda wildcards: config["fastqdir"] + config["samples"][wildcards.sample]["reverse"]
    output:
        forward = WORKING_DIR + "trimmed/{sample}_forward.fastq",
        reverse = WORKING_DIR + "trimmed/{sample}_reverse.fastq",
        forwardUnpaired  = WORKING_DIR + "trimmed/{sample}_forward_unpaired.fastq",
        reverseUnpaired = WORKING_DIR + "trimmed/{sample}_reverse_unpaired.fastq",
    message:"Trimming {wildcards.sample} using Trimmomatic"
    log:"results/trimlogs/{sample}.trimlog"
    params :
        seedMisMatches =            str(config['trimmomatic']['seedMisMatches']),
        palindromeClipTreshold =    str(config['trimmomatic']['palindromeClipTreshold']),
        simpleClipThreshhold =      str(config['trimmomatic']['simpleClipThreshold']),
        LeadMinTrimQual =           str(config['trimmomatic']['LeadMinTrimQual']),
        TrailMinTrimQual =          str(config['trimmomatic']['TrailMinTrimQual']),
        windowSize =                str(config['trimmomatic']['windowSize']),
        avgMinQual =                str(config['trimmomatic']['avgMinQual']),
        minReadLen =                str(config['trimmomatic']['minReadLength']),
        phred = 		    str(config["trimmomatic"]["phred"])
    shell:
        "java -jar {TRIMMOMATIC} PE {params.phred} -threads {THREADS} "
        "{input.forward} {input.reverse} "
        "{output.forward} {output.forwardUnpaired} "
        "{output.reverse} {output.reverseUnpaired} "
        "ILLUMINACLIP:{ADAPTERFILE}:{params.seedMisMatches}:{params.palindromeClipTreshold}:{params.simpleClipThreshhold} "
        "LEADING:{params.LeadMinTrimQual} "
        "TRAILING:{params.TrailMinTrimQual} "
        "SLIDINGWINDOW:{params.windowSize}:{params.avgMinQual} "
        "MINLEN:{params.minReadLen} 2>{log}"



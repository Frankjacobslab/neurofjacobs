# Snakefile
# Tells which files to generate as specified by the rule 'all'

# Snakefile to quality check and estimate counts from RNA-Seq data on a reference genome (e.g. human genome hg19)
# Tells which files to generate as specified by the rule 'all'

import os
import datetime

#########################
## Pipeline configuration
#########################

# configuration file
configfile: "config.yaml"

# working directory (to clean afterwards)
# result directory (to keep) with the time when analysis started
WORKING_DIR = config["workdir"]
now = datetime.datetime.now() # get current time
RESULT_DIR = config["resultdir"] + str(now.year) + "-" + str(now.month) + "-" + str(now.day) + "/"


# Number of CPU (threads)
THREADS = config["threads"]

# Trimmomatic
ADAPTERFILE = config["trimmomatic"]["adapters"]
TRIMMOMATIC = config["trimmomatic"]["jarfile"]

##################
## Desired outputs
##################
FASTQC_REPORTS = expand(RESULT_DIR + "fastqc/{step}/{sample}/{pair}/{sample}_{pair}_fastqc.html",step=["raw","trimmed"],sample=config["samples"],pair=["forward","reverse"])
COUNTS = [RESULT_DIR + f for f in ["counts/gene_counts.txt","counts/repeat_counts.txt"]] 
BIGWIGS = expand(RESULT_DIR + "mapped/{sample}_accepted_hits.sorted.bw",sample=config["samples"])

MASTER_FILES = [RESULT_DIR + f for f in ["Snakefile","config.yaml","environment.yaml"]]

rule all:
	input:
		COUNTS,
		BIGWIGS,
		MASTER_FILES 
	message: "RNA-Seq pipeline has been successfully run"

#######################
##  copy master files
#######################
rule copy_master_files:
    output:
        RESULT_DIR + "Snakefile",
        RESULT_DIR + "config.yaml",
        RESULT_DIR + "environment.yaml"
    message:"copying master files (Snakefile and configuration files)"
    shell:
        "cp Snakefile {RESULT_DIR};"
        "cp config.yaml {RESULT_DIR};"
        "cp environment.yaml {RESULT_DIR}"

#########
## bigWig
#########
rule convert_to_bigWig: 
    input:
        bedgraph = WORKING_DIR + "mapped/{sample}_accepted_hits.sorted.bg",
        chroms = "chromSizes.tab"
    output:
        RESULT_DIR + "mapped/{sample}_accepted_hits.sorted.bw"
    message:"converting bedGraph files for {wildcards.sample} strand to bigWig format"
    shell:
        "bedGraphToBigWig {input.bedgraph} {input.chroms} {output}"        

rule generate_chrom_sizes:
    input:
        genome2bit = config["refseqs"]["genome2bit"]
    output:
        "chromSizes.tab"
    message:"generating chromosome sizes"
    shell:"twoBitInfo {input} {output}"

rule sort_bedgraph:
    input:
         WORKING_DIR + "mapped/{sample}_accepted_hits.bg"
    output:
         WORKING_DIR + "mapped/{sample}_accepted_hits.sorted.bg"
    message:"sorting {wildcards.sample} bedGraph file"
    shell:
        "bedSort {input} {output}"   

rule make_bedgraph:
    input:
        bam = WORKING_DIR + "mapped/{sample}_accepted_hits.sorted.bam",
        genome = config["refseqs"]["genomefasta"]
    output:
        WORKING_DIR + "mapped/{sample}_accepted_hits.bg"
    message:"computing {wildcards.sample} genome coverage values"
    shell:
        "samtools view -b {input.bam} | bedtools genomecov "
        "-split " 						# split option necessary for RNA-Seq
        "-bg "							# to report coverage in bedgraph format
        "-ibam stdin "						# reads file directly from standard-in
        "-g {input.genome} > {output}" 




# To be discussed with Nina
#rule separate_strands:
#    input:
#        WORKING_DIR + "mapped/{sample}_accepted_hits.bam"
#    output:
#        pos = WORKING_DIR + "mapped/{sample}/accepted_hits.bam",#
#
#    message:"split {wildcards.sample} bam file into positive and negative strands"
#    shell:
#        "samtools view -f 99  

################################################
## Count read alignments per feature (e.g. gene)
################################################
rule count_repeats:
    input:
        bams = expand(WORKING_DIR + "mapped/{sample}_accepted_hits.sorted.bam",sample=config["samples"].keys()),
        annotation = config["annotations"]["gtf4repeats"],
        genome = config["refseqs"]["genomefasta"]
    output:
        RESULT_DIR + "counts/repeat_counts.txt"
    message:"summarizing read counts for repeats"
    shell:
        "featureCounts "
        "-f "				# summarize only at exon level
        "-T {THREADS} "
        "-G {input.genome} "		# ref genome sequence
        "-a {input.annotation} "	# annotation 
        "-F GTF "			# SAF or GTF (by default GTF)
        "-o {output} "
        "{input.bams}"               	# can process more than one BAM file at once 

rule count_genes:
    input:
        bams = expand(WORKING_DIR + "mapped/{sample}_accepted_hits.sorted.bam",sample=config["samples"].keys()),
        annotation = config["annotations"]["refseqFromSubread"],
        genome = config["refseqs"]["genomefasta"]
    output:
        RESULT_DIR + "counts/gene_counts.txt"
    message:"summarizing read counts for genes"
    shell:
        "featureCounts "
        "-t exon "			# specify how to count reads at feature level (e.g. exon)
        "-g gene_id " 			# specify how to count reads at meta-feature level (e.g. gene)
        "-T {THREADS} "
        "-G {input.genome} "		# ref genome sequence
        "-a {input.annotation} "	# annotation 
        "-F SAF "			# SAF or GTF (by default GTF)
        "-o {output} "
        "{input.bams}"               	# can process more than one BAM file at once 
        
#############################################
# Reads alignment against genome using hisat2
#############################################
rule sort_and_rename_bams: # for count and coverage computations
    input:
        WORKING_DIR + "mapped/{sample}/accepted_hits.bam"
    output:
        WORKING_DIR + "mapped/{sample}_accepted_hits.sorted.bam"
    message:"sorting {wildcards.sample} bam file"
    shell:
        "samtools sort -l 0 " 	# 0 for uncompressed (temporary file)
        "-m 4G "		# memory for sorting
        "-O bam "		# output format
        "-@ {THREADS} "		# number of threads for sorting BAM file
        "-o {output} "		# output file
        "{input}"

rule hisat:
    input:
        forward = WORKING_DIR + "trimmed/{sample}_forward.fastq",
        reverse = WORKING_DIR + "trimmed/{sample}_reverse.fastq",
        index = [WORKING_DIR + "index/genome" + "." + str(n) + ".ht2" for n in range(1,9)]
    output:
        WORKING_DIR + "mapped/{sample}/accepted_hits.bam"
    message:"mapping {wildcards.sample} reads using hisat2"
    params:
        libtype = config["hisat2"]["library_type"],
        speed = config["hisat2"]["speed"],
        min_intron = config["hisat2"]["min_intron_length"],
        max_intron = config["hisat2"]["max_intron_length"],
        index = WORKING_DIR + "index/genome"
    log: 
        RESULT_DIR + "mapped/{sample}_log.out"
    shell:
        "hisat2 -x {params.index} "
        "-I {params.min_intron} "
        "-X {params.max_intron} "
        "--threads {THREADS} "
        "{params.libtype} " 
        "-1 {input.forward} "
        "-2 {input.reverse} "
        "-S {output} 2>{log} "

rule make_genome_index:
    input:
        genome = config["refseqs"]["genomefasta"]
    output:
        index = [WORKING_DIR + "index/genome" + "." + str(n) + ".ht2" for n in range(1,9)]
    message:"building genome index with hisat2"
    params:
       index_base = WORKING_DIR + "index/genome"
    shell:
        "hisat2-build --quiet {input.genome} {params.index_base}"

################################
## Fastqc reports after trimming
################################
rule fastqc_after_trimming:
    input:
        WORKING_DIR + "trimmed/{sample}_{pair}.fastq"
    output:
        RESULT_DIR + "fastqc/trimmed/{sample}/{pair}/{sample}_{pair}_fastqc.html"
    message:"generating fastqc report for trimmed reverse {wildcards.sample} reads"
    params:
        "fastqc/trimmed/{sample}/{pair}/"
    shell:
        "fastqc --threads {THREADS} --outdir={params} {input}"
    
###########
## Trimming
###########
rule trimmomaticPaired:
    input:
        ADAPTERFILE,
        forward = lambda wildcards: config["fastqdir"] + config["samples"][wildcards.sample]["forward"],
        reverse = lambda wildcards: config["fastqdir"] + config["samples"][wildcards.sample]["reverse"]
    output:
        forward = WORKING_DIR + "trimmed/{sample}_forward.fastq",
        reverse = WORKING_DIR + "trimmed/{sample}_reverse.fastq",
        forwardUnpaired  = WORKING_DIR + "trimmed/{sample}_forward_unpaired.fastq",
        reverseUnpaired = WORKING_DIR + "trimmed/{sample}_reverse_unpaired.fastq",
    message:"Trimming {wildcards.sample} using Trimmomatic"
    log:"results/trimlogs/{sample}.trimlog"
    params :
        seedMisMatches =            str(config['trimmomatic']['seedMisMatches']),
        palindromeClipTreshold =    str(config['trimmomatic']['palindromeClipTreshold']),
        simpleClipThreshhold =      str(config['trimmomatic']['simpleClipThreshold']),
        LeadMinTrimQual =           str(config['trimmomatic']['LeadMinTrimQual']),
        TrailMinTrimQual =          str(config['trimmomatic']['TrailMinTrimQual']),
        windowSize =                str(config['trimmomatic']['windowSize']),
        avgMinQual =                str(config['trimmomatic']['avgMinQual']),
        minReadLen =                str(config['trimmomatic']['minReadLength']),
        phred = 		    str(config["trimmomatic"]["phred"])
    shell:
        "java -jar {TRIMMOMATIC} PE {params.phred} -threads {THREADS} "
        "{input.forward} {input.reverse} "
        "{output.forward} {output.forwardUnpaired} "
        "{output.reverse} {output.reverseUnpaired} "
        "ILLUMINACLIP:{ADAPTERFILE}:{params.seedMisMatches}:{params.palindromeClipTreshold}:{params.simpleClipThreshhold} "
        "LEADING:{params.LeadMinTrimQual} "
        "TRAILING:{params.TrailMinTrimQual} "
        "SLIDINGWINDOW:{params.windowSize}:{params.avgMinQual} "
        "MINLEN:{params.minReadLen} 2>{log}"

################################
## Fastqc reports before trimming
################################
rule fastqc_before_trimming:
    input:
        forward = lambda wildcards: config["fastqdir"] + config["samples"][wildcards.sample]["forward"][wildcards.pair],
        reverse = lambda wildcards: config["fastqdir"] + config["samples"][wildcards.sample]["reverse"][wildcards.pair]
    output:
        RESULT_DIR + "fastqc/raw/{sample}/{pair}/{sample}_{pair}_fastqc.html"
    message:"generating fastqc report for original untrimmed {wildcards.sample} reads"
    params:
        "fastqc/raw/{sample}/{pair}/"
    shell:
        "fastqc --threads {THREADS} --outdir={params} {input}"

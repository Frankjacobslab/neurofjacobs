---
title: "Differential expression using DESeq2"
author: "Marc Galland"
date: "`r Sys.Date()`"
output:
    html_document:
        number_sections: yes
        toc: yes
        toc_depth: 2  
params:
  counts: "../../../results/20160928_counts/counts.txt"
  design: "../../../results/20160928_counts/design.txt"
---
# introduction
DESeq2 performs a differential expression analysis at the gene level using __raw counts__ from RNA-Seq reads aligned to a reference sequence (genome in most cases) and a __experimental design__ file that lists factors of interest. 

From the [documentation](https://bioconductor.org/packages/release/bioc/html/DESeq2.html): 
> It uses the negative binomial distribution and a shrinkage estimator for the distribution variance. 

## Original paper and further reading
*  Please cite Anders & Huber [original paper](https://www.ncbi.nlm.nih.gov/pubmed/20979621)
*  A detailed protocol for RNA-Seq based differential expression can be found [here](https://www.ncbi.nlm.nih.gov/pubmed/23975260)


# configuration
## Load libraries
```{r load libraries}
library(DESeq2)
library(ezknitr)
library(dplyr)
library(pheatmap)
library(RColorBrewer)
```

# DESeq analysis

## Data input
Loads raw counts and experimental design file. Values are defined in the Rmarkdown file header (YAML header)
```{r load data and create Count Data Set object}
# import counts
counts = read.delim(file = params$counts,sep = "\t",stringsAsFactors = F)
row.names(counts)=counts[,1]
counts[,1] <- NULL

# experiment design
design = read.delim(file = params$design,sep="\t",stringsAsFactors=F)
row.names(design)=design$sample
design$sample <- NULL

# convert to a CountDataSet object 
cds = DESeqDataSetFromMatrix(countData = counts,colData = design,design = ~ condition)
```

## scaling and dispersion computations 
From the paper [here](https://www.ncbi.nlm.nih.gov/pubmed/23975260)
> Analogously, DESeq defines a virtual reference sample by taking the median of each gene’s values across samples and then computes size factors as the median of ratios of each sample to the reference sample. Generally, the ratios of the size factors should roughly match the ratios of the library sizes. Dividing each column of the count table by the corresponding size factor yields normalized count values, which can be scaled to give a counts per million interpretation (see also edgeR’s cpm function). From an M (log ratio) versus A (log expression strength) plot, count data sets typically show a (left-facing) trombone shape, reflecting the higher variability of log ratios at lower counts (Fig. 6). In addition, points will typically be centered around a log ratio of 0 if the normalization factors are calculated appropriately, although this is just a general guide.

```{r scaling and dispersion}
# estimate size factors
cds = estimateSizeFactors(cds)

# print these size factors (should be quite close to the number of reads in the libraries)
sizeFactors(cds)
```

Calculate dispersion: sample-to-sample variation + uncertainty in measuring a concentration)
```{r}
# calculate dispersion for each gene
cds = estimateDispersions(cds)

# plot the per-gene estimates against the mean normalized counts per gene
# overlay the fitted curve 
plotDispEsts(cds)
```


## Principal Component Analysis
The `rlog` function:
> This function transforms the count data to the log2 scale in a way which minimizes differences between samples for rows with small counts, and which normalizes with respect to library size. The rlog transformation produces a similar variance stabilizing effect as varianceStabilizingTransformation, though rlog is more robust in the case when the size factors vary widely. The transformation is useful when checking for outliers or as input for machine learning techniques such as clustering or linear discriminant analysis. rlog takes as input a DESeqDataSet and returns a RangedSummarizedExperiment object.

The `varianceStabilizingTransformation` function
> This function calculates a variance stabilizing transformation (VST) from the fitted dispersion-mean relation(s) and then transforms the count data (normalized by division by the size factors or normalization factors), yielding a matrix of values which are now approximately homoskedastic (having constant variance along the range of mean values). The transformation also normalizes with respect to library size. The rlog is less sensitive to size factors, which can be an issue when size factors vary widely. These transformations are useful when checking for outliers or as input for machine learning techniques such as clustering or linear discriminant analysis.

The `blind=TRUE/FALSE` option	
> logical, whether to blind the transformation to the experimental design. blind=TRUE should be used for comparing samples in an manner unbiased by prior information on samples, for example to perform sample QA (quality assurance). blind=FALSE should be used for transforming data for downstream analysis, where the full use of the design information should be made. blind=FALSE will skip re-estimation of the dispersion trend, if this has already been calculated. If many of genes have large differences in counts due to the experimental design, it is important to set blind=FALSE for downstream analysis.

```{r PCA}
# transform 
rld <- rlog(cds,blind = F)
plotPCA(rld, intgroup = c("condition"))

# extract values for clustering...
rlog_values = assay(rld)

# heatmap and clustering of all genes (takes a lot of time)
#pheatmap(rlog_values)

# sample to sample clustering
sampleDists <- dist(t(assay(rld)))
sampleDistMatrix <- as.matrix(sampleDists)
rownames(sampleDistMatrix) <- rld$condition
colnames(sampleDistMatrix) <- NULL
  
# heatmap
colors <- colorRampPalette( rev(brewer.pal(9, "Blues")) )(255)
pheatmap(sampleDistMatrix,
clustering_distance_rows=sampleDists,
clustering_distance_cols=sampleDists,
col=colors)
```

## Differential analysis 
This function performs a default differential expression analysis through the steps:
*  estimation of size factors: estimateSizeFactors
*  estimation of dispersion: estimateDispersions
*  Negative Binomial GLM fitting and Wald statistics: nbinomWaldTest
### Binomial test
```{r}
# Performs a differential analysis on raw counts using Wald test 
test = nbinomWaldTest(cds)
res_D0vsD28 = results(test,contrast = c("condition","D0","D28"))
res_D0vsD42 = results(test,contrast = c("condition","D0","D42"))


# cds_wald = DESeq(cds,
#             test = "Wald", 
#             fitType = c("parametric"),
#             full = design(cds),
#             quiet = FALSE,
#             minReplicatesForReplace = 7,
#             # expanded includes an indicator variable for each level of factors
#             modelMatrixType = "expanded", 
#             parallel = FALSE,
#             BPPARAM = bpparam()
# )

# extract results
resD0vsD28 = results(cds_wald,contrast = c("condition","D0","D28"),test = "Wald")
resD0vsD42= results(cds_wald,contrast = c("condition","D0","D28"),test="Wald")
```

### Likelihood test
```{r}
# Likelihood test ratio `LRT`
cds_lrt = DESeq(cds,test = "LRT",reduced= ~ 1,quiet = F)

# extract results
res_lrt = results(cds_lrt)
resOrdered <- res_lrt[order(res_lrt$padj),]

# write to table
write.table(as.data.frame(resOrdered),file="diff_expr_LRT.txt",quote = F,row.names = T ,sep = "\t")
```

 
# session info 
Records package versions, R version...
```{r session}
sessionInfo()
```

